{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSCI 285 Exam 1\n",
    "\n",
    "# Kaden Franklin - 9/27/2022\n",
    "\n",
    "https://hendrix-cs.github.io/csci285/exams/exam1.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Import seaborn\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Import SciKitLearn functions\n",
    "from sklearn.datasets import make_blobs, make_regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# and finally import numpy\n",
    "import numpy as np\n",
    "\n",
    "# Apply the default theme\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part  1 - Generation & visualization of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(10 points) Using python and/or pandas, create a data frame that has the following schema,\n",
    "\n",
    "                id\tage\tincome\n",
    "\n",
    "The data contained in this data frame should satisfy the following constraints,\n",
    "\n",
    "id should increment from 1 to 10,000. This does not need to be a column but can serve as the index of the data frame.\n",
    "age should be randomly generated by sampling the “standard normal” distribution. Ages should approximately fall between 20 and 30 years old and have a mean of 25. (its fine if your numbers look slightly different. the goal here is to generate a normal distribution of ages that looks realistic)\n",
    "income should be generated using the same method as age but with income approximately falling between 25k and 45k with a mean of 35k. Again, it is fine if your numbers vary a bit as long as income is normally distributed.\n",
    "\n",
    "\n",
    "(5 points) Display the minimum, maximum, and average (mean) values of age and income.\n",
    "\n",
    "(10 points) Draw two histograms, using seaborn, in order to show that your data is normally distributed. Make sure that your axes are labeled and that you set a title for each chart. Increase the size and aspect ratio to improve visibility.\n",
    "\n",
    "(10 points) Draw a scatter plot, using seaborn, that plots age vs. income. Make sure that your axes are labeled and that you set a title. Increase the size and aspect ratio to improve visibility.\n",
    "\n",
    "(10 points) Create a new column on your data frame, called sector, that contains one of four values: “jazz”, “puck”, “camp”, and “flub”. Draw another scatter plot similar to one you created in (3) except that “sector” is displayed using color.\n",
    "Assign “jazz” if age > 25 and income > 35k Assign “puck” if age < 25 and income > 35k Assign “camp” if age > 25 and income < 35k Assign “flub” to all remaining points\n",
    "\n",
    "(5 points) Display the number of points in each sector where income is greater than 40k. If you were unable to do 1.4, then simply display the number of points where income is greater than 40k (sans sector).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      age income\n",
      "0     NaN    NaN\n",
      "1     NaN    NaN\n",
      "2     NaN    NaN\n",
      "3     NaN    NaN\n",
      "4     NaN    NaN\n",
      "...   ...    ...\n",
      "9995  NaN    NaN\n",
      "9996  NaN    NaN\n",
      "9997  NaN    NaN\n",
      "9998  NaN    NaN\n",
      "9999  NaN    NaN\n",
      "\n",
      "[10000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "dat = []\n",
    "deez = []\n",
    "doze = []\n",
    "newts = np.random.normal(25, 5, 10000)\n",
    "\n",
    "for x in range(10000):\n",
    "    dat.append(x)\n",
    "    \n",
    "dis = {'age': newts, 'income': doze }\n",
    "    \n",
    "# create a dataframe of 10000 values, make 10000 age values by sampling the standard distribution.\n",
    "# ages should be between 20 - 30 and have a mean of 25\n",
    "# income generated in the same way, just between 25k -45k with a mean of 35k\n",
    "\n",
    "examframe = pd.DataFrame(columns = dis, index = dat)  \n",
    "print(examframe)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicities sake I have chose to remove the id row, it is not needed to index the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mean and standard deviation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_t.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_t.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - unknown visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The iris flower dataset is a multivariate data set introduced by the British statistician and biologist Ronald Fisher in his 1936 paper “The use of multiple measurements in taxonomic problems”. It is sometimes called Anderson’s Iris data set because Edgar Anderson collected the data to quantify the morphologic variation of Iris flowers of three related species. The data set consists of 50 samples from each of three species of Iris (Iris Setosa, Iris virginica, and Iris versicolor). Four features were measured from each sample: the length and the width of the sepals and petals, in centimeters.\n",
    "\n",
    "(5 points) Load iris.csv into a pandas data frame. Record the shape of the data frame.\n",
    "\n",
    "(5 points) Display the first 10 rows of the dataset. Display the last 5 rows of the dataset.\n",
    "\n",
    "(5 points) Display the count of each value in the species column.\n",
    "\n",
    "(5 points) Display the data types of the columns.\n",
    "\n",
    "(10 points) Draw a box plot, using seaborn, of iris petal width (cm) vs. species. Make sure that your axes are labeled and that you set a title. Increase the size and aspect ratio to improve visibility. What differences do you noticed in this plot?\n",
    "\n",
    "(10 points) Draw a pairwise plot, using seaborn, of the four numerical columns and the one categorical column. Make sure to color by the categorical column. What do you notice about the dataset through analyzing this array of charts?\n",
    "\n",
    "(10 points) Draw a scatter plot that includes linear regressions, using seaborn, of two features that appear linearly related. Color by species. Increase the size and aspect ratio to improve visibility. Make sure that your axes are labeled and that you set a title. What conclusions can you draw from this plot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_t['chest_pain'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "c_t['rest_ecg'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_t['heart_disease'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# three categorical against five numeric\n",
    "# 'chest_pain', 'rest_ecg', 'heart_disease'\n",
    "# 'age', 'rest_bps', 'cholesteral', 'maximum_heart_rate', 'vessels'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dis = ['chest_pain', 'rest_ecg', 'heart_disease']\n",
    "# dat = ['age', 'rest_bps', 'cholesterol', 'maximum_heart_rate', 'vessels']\n",
    "\n",
    "# for x, y in enumerate(dat):\n",
    "#     sns.pairplot(c_t, x_vars= dis[x], y_vars= y )\n",
    "    \n",
    "plot = sns.pairplot(\n",
    "    data = c_t[['age', 'rest_bps', 'cholesterol', 'maximum_heart_rate', 'vessels', 'chest_pain']],\n",
    "    hue = 'chest_pain',\n",
    "    markers = True,\n",
    "    corner = True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = sns.pairplot(\n",
    "    data = c_t[['age', 'rest_bps', 'cholesterol', 'maximum_heart_rate', 'vessels', 'rest_ecg']],\n",
    "    hue = 'rest_ecg',\n",
    "    markers = True,\n",
    "    corner = True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = sns.pairplot(\n",
    "    data = c_t[['age', 'rest_bps', 'cholesterol', 'maximum_heart_rate', 'vessels', 'heart_disease']],\n",
    "    hue = 'heart_disease',\n",
    "    markers = True,\n",
    "    corner = True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# three categorical against five numeric\n",
    "# 'chest_pain', 'rest_ecg', 'heart_disease'\n",
    "# 'age', 'rest_bps', 'cholesterol', 'maximum_heart_rate', 'vessels'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But First...\n",
    "\n",
    "In case you were unaware, it is important to scale your data. So that when clustering different types of data, they are compared with relatively the same magnitude. This means larger values will not simply eclipse other ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['age', 'rest_bps', 'cholesterol', 'maximum_heart_rate', 'vessels']\n",
    "c_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in columns:\n",
    "    if c_t[col].dtype == str:\n",
    "        c_t[col].str.replace(\"[.,]\",\"\")\n",
    "        print('dededed')\n",
    "    c_t[col] = pd.to_numeric(c_t[col], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_t.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "c_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=2).fit(c_t)\n",
    "\n",
    "y = kmeans.fit_predict(c_t[['age', 'rest_bps', 'cholesterol', 'maximum_heart_rate', 'vessels']])\n",
    "\n",
    "# drop any nan values\n",
    "# remember to scale your features, and store data in two new columns, appended to the original dataframe\n",
    "\n",
    "# cluster - 0 or 1 and is the resulting labels from running K-Means.\n",
    "\n",
    "# prediction - 0s and 1s into True/False values that align with the ground truth heart_disease column.\n",
    "\n",
    "c_t['Cluster'] = y\n",
    "\n",
    "# compare & contrast\n",
    "\n",
    "# scaling so all datapoints are weighted the same\n",
    "# held between -1 & 1\n",
    "\n",
    "\n",
    "c_t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_t.groupby(['heart_disease',  'Cluster']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 - Clustering & PCA\n",
    "Continuing with the iris flower data set from Part 2, scale your features and use KMeans to cluster your data into 3 clusters. Use PCA to decompose your features into two dimensions. Draw a scatter plot for your two PCA dimensions and color the plot using the clustering results. Discuss the results from creating this chart.\n",
    "\n",
    "Discuss why k=3 clusters is the right choice. How can you show that k=3 is the right choice using the the principle of inertia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://nbviewer.org/github/Hendrix-CS/csci285/blob/master/assets/notebooks/Distance_Measures.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://nbviewer.org/github/Hendrix-CS/csci285/blob/master/assets/notebooks/K-Means_Considerations.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://datascience.stackexchange.com/questions/48693/perform-k-means-clustering-over-multiple-columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://nbviewer.org/github/Hendrix-CS/csci285/blob/master/assets/notebooks/Datasets.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://nbviewer.org/github/Hendrix-CS/csci285/blob/master/assets/notebooks/Lemurs.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion Questions\n",
    "What is feature scaling and why is it important to do as a preprocessing step?\n",
    "\n",
    "What is meant by an n-dimensional Euclidean space ? Is the iris dataset an example of a Euclidean space? What’s an example of a non-Euclidean space that we discussed in class or examined in lab? What does it matter?\n",
    "\n",
    "Qualitatively, what is the difference between L1 and L2 distance measures?\n",
    "\n",
    "What is meant by the “curse of dimensionality”? Does the iris dataset suffer from this “curse”?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

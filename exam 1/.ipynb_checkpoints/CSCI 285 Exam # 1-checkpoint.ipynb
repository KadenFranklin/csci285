{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSCI 285 Exam 1\n",
    "\n",
    "# Kaden Franklin - 9/27/2022\n",
    "\n",
    "https://hendrix-cs.github.io/csci285/exams/exam1.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Import seaborn\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Import SciKitLearn functions\n",
    "from sklearn.datasets import make_blobs, make_regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# and finally import numpy\n",
    "import numpy as np\n",
    "\n",
    "# Apply the default theme\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part  1 - Generation & visualization of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(10 points) Using python and/or pandas, create a data frame that has the following schema,\n",
    "\n",
    "                id\tage\tincome\n",
    "\n",
    "The data contained in this data frame should satisfy the following constraints,\n",
    "\n",
    "id should increment from 1 to 10,000. This does not need to be a column but can serve as the index of the data frame.\n",
    "age should be randomly generated by sampling the “standard normal” distribution. Ages should approximately fall between 20 and 30 years old and have a mean of 25. (its fine if your numbers look slightly different. the goal here is to generate a normal distribution of ages that looks realistic)\n",
    "income should be generated using the same method as age but with income approximately falling between 25k and 45k with a mean of 35k. Again, it is fine if your numbers vary a bit as long as income is normally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dat = []\n",
    "deez = []\n",
    "inc = []\n",
    "newts = np.random.normal(25, 5, 10000)\n",
    "\n",
    "for x in range(10000):\n",
    "    dat.append(x)\n",
    "    \n",
    "dis = {'age': newts, 'income': inc }\n",
    "    \n",
    "# create a dataframe of 10000 values, make 10000 age values by sampling the standard distribution.\n",
    "# ages should be between 20 - 30 and have a mean of 25\n",
    "# income generated in the same way, just between 25k -45k with a mean of 35k\n",
    "\n",
    "examframe = pd.DataFrame(columns = dis, index = dat)  \n",
    "print(examframe)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicities sake I have chose to remove the id row, it is not needed to index the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (5 points) Display the minimum, maximum, and average (mean) values of age and income.\n",
    "examframe.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (10 points) Draw two histograms, using seaborn, in order to show that your data is normally distributed\n",
    "# Make sure that your axes are labeled and that you set a title for each chart. \n",
    "# Increase the size and aspect ratio to improve visibility.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (10 points) Draw a scatter plot, using seaborn, that plots age vs. income. \n",
    "# Make sure that your axes are labeled and that you set a title. \n",
    "# Increase the size and aspect ratio to improve visibility.\n",
    "\n",
    "scatter = sns.relplot(\n",
    "    data=pcadf, \n",
    "    x=\"age\", \n",
    "    y=\"income\", \n",
    "    kind=\"scatter\",\n",
    "    height=10,\n",
    "    aspect=1.5,\n",
    "    hue= \n",
    ").set(\n",
    "    title=\"Heart disease vs. Cluster\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (10 points) Create a new column on your data frame, called sector, that contains one of four values:\n",
    "# “jazz”, “puck”, “camp”, and “flub”.\n",
    "# Draw another scatter plot similar to one you created in (3) except that “sector” is displayed using color\n",
    "# Assign “jazz” if age > 25 and income > 35k \n",
    "# Assign “puck” if age < 25 and income > 35k \n",
    "# Assign “camp” if age > 25 and income < 35k \n",
    "# Assign “flub” to all remaining points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (5 points) Display the number of points in each sector where income is greater than 40k. \n",
    "# If you were unable to do 1.4, then simply display the number of points where income is greater than 40k."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://numpy.org/doc/stable/reference/random/generated/numpy.random.normal.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Iris Flower dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The iris flower dataset is a multivariate data set introduced by the British statistician and biologist Ronald Fisher in his 1936 paper “The use of multiple measurements in taxonomic problems”. It is sometimes called Anderson’s Iris data set because Edgar Anderson collected the data to quantify the morphologic variation of Iris flowers of three related species. The data set consists of 50 samples from each of three species of Iris (Iris Setosa, Iris virginica, and Iris versicolor). Four features were measured from each sample: the length and the width of the sepals and petals, in centimeters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (5 points) Load iris.csv into a pandas data frame. Record the shape of the data frame.\n",
    "\n",
    "iris = pd.read_csv(\"archive//IRIS.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (5 points) Display the first 10 rows of the dataset.\n",
    "\n",
    "columns = ['sepal_length','sepal_width','petal_length','petal_width']\n",
    "           \n",
    "# we will use this list later, but this is the numeric features\n",
    "\n",
    "ding = iris.sample(10)\n",
    "ding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the last 5 rows of the dataset.\n",
    "iris.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# (5 points) Display the count of each value in the species column.\n",
    "iris['species'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris['species'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(5 points) Display the data types of the columns.\n",
    "iris.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (10 points) Draw a box plot, using seaborn, of iris petal width (cm) vs. species.\n",
    "# Make sure that your axes are labeled and that you set a title. \n",
    "# Increase the size and aspect ratio to improve visibility. \n",
    "# What differences do you noticed in this plot?\n",
    "\n",
    "sns.boxplot(\n",
    "    data=iris, \n",
    "    x=\"sepal_width\",\n",
    "    y=\"species\", \n",
    "    width = 0.75\n",
    ").set(\n",
    "    title='species vs sepal width [A box plot]')\n",
    "\n",
    "#  i notice that iris-versicolor have the smallest width pedals generally, with iris-verginica following, and lastly iris-sertosa having the longest pedal width."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.groupby('species')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (10 points) Draw a pairwise plot, using seaborn, of the four numerical columns and the one categorical column. \n",
    "# Make sure to color by the categorical column. What do you notice about the dataset through analyzing this array of charts?\n",
    "\n",
    "plot = sns.pairplot(\n",
    "    data = iris[columns],\n",
    "    hue = 'species',\n",
    "    markers = True,\n",
    "    corner = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (10 points) Draw a scatter plot that includes linear regressions, using seaborn, of two features that appear linearly related.\n",
    "# Color by species. Increase the size and aspect ratio to improve visibility. \n",
    "# Make sure that your axes are labeled and that you set a title. What conclusions can you draw from this plot?\n",
    "\n",
    "scatter = sns.relplot(\n",
    "    data=iris, \n",
    "    x=\"sepal_length\", \n",
    "    y=\"petal_width\", \n",
    "    kind=\"scatter\",\n",
    "    height=10,\n",
    "    aspect=1.5, \n",
    "    hue=\"species\"\n",
    ").set(\n",
    "    title=\"Sepal Length vs Petal Width\"\n",
    ")\n",
    "\n",
    "# the conclusions I can draw from this plot are the same as that of the box plot, the size of the respective petals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 - Clustering & PCA\n",
    "Continuing with the iris flower data set from Part 2, scale your features and use KMeans to cluster your data into 3 clusters. Use PCA to decompose your features into two dimensions. \n",
    "\n",
    "Draw a scatter plot for your two PCA dimensions and color the plot using the clustering results. Discuss the results from creating this chart.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = iris.dropna(subset = columns).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = iris.loc [:, columns].values\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar = StandardScaler()\n",
    "\n",
    "x = scalar.fit_transform(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=3)\n",
    "result = kmeans.fit(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.cluster_centers_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discuss why k=3 clusters is the right choice. How can you show that k=3 is the right choice using the the principle of inertia.\n",
    "\n",
    "k=3 clusters is the correct choice because there are three distinct species of flowers which we are analyzing in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris[columns] = scalar.fit_transform(iris[columns])\n",
    "\n",
    "y = kmeans.fit_predict(iris[columns])\n",
    "\n",
    "iris['clusters'] = y\n",
    "\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.groupby(['species',  'clusters']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2).fit(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(\n",
    "    n_components=3\n",
    ")\n",
    "\n",
    "principal_components = pca.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf = pd.DataFrame(data= principal_components,\n",
    "                       columns=[\"PCA 1\", \"PCA 2\"])\n",
    "\n",
    "newdf['clusters'] = iris['clusters']\n",
    "newdf['species'] = iris['species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter = sns.relplot(\n",
    "    data=iris, \n",
    "    x=\"PCA 1\", \n",
    "    y=\"PCA 2\", \n",
    "    kind=\"scatter\",\n",
    "    height=10,\n",
    "    aspect=1.5, \n",
    "    hue=\"species\"\n",
    ").set(\n",
    "    title=\"Sepal Length vs Petal Width\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is feature scaling and why is it important to do as a preprocessing step?\n",
    "\n",
    "feature scaling puts each variable on a similiar weight, so that values that are simply larger numbers do not eclipse smaller ones when comparing the values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is meant by an n-dimensional Euclidean space ? Is the iris dataset an example of a Euclidean space? \n",
    "\n",
    "n-dimensional euclidean space can be described as space where vectors exist as points of n real numbers.\n",
    "\n",
    "The iris dataset is in fact an example of euclidean space, we can assume the values between numbers exist and average them. Clustering and regression algorithms work on it. \n",
    "\n",
    "What’s an example of a non-Euclidean space that we discussed in class or examined in lab? What does it matter?\n",
    "\n",
    "An example of non euclidean space that we talked about in class was time and date datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qualitatively, what is the difference between L1 and L2 distance measures?\n",
    "\n",
    "L1 distance measures deal with euclideans space\n",
    "\n",
    "L2 distance measures deal with non euclidean space\n",
    "\n",
    "What is meant by the “curse of dimensionality”? Does the iris dataset suffer from this “curse”?\n",
    "\n",
    "\"curse of dimesnionality\"- as explained by wikipedia refers to various problems encountered when working with data containing many axis. To quote the cite 'The common theme of these problems is that when the dimensionality increases, the volume of the space increases so fast that the available data become sparse. In order to obtain a reliable result, the amount of data needed often grows exponentially with the dimensionality. Also, organizing and searching data often relies on detecting areas where objects form groups with similar properties; in high dimensional data, however, all objects appear to be sparse and dissimilar in many ways, which prevents common data organization strategies from being efficient.'\n",
    "\n",
    "yes the iris dataset suffers from the \"curse of dimesnionality\", it has multiple rows and columns \n",
    "\n",
    "###### -  i did use one source:\n",
    "https://en.wikipedia.org/wiki/Curse_of_dimensionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
